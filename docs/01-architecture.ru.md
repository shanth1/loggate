# 1. Архитектура системы LogGate

## 1.1. Концепция

LogGate спроектирован как промежуточный слой (middleware) между источниками логов (приложениями) и системами их хранения. Его основная задача — снять с приложений ответственность за то, _куда_ и _как_ доставлять логи. Приложения просто отправляют структурированные сообщения по UDP, а LogGate берет на себя маршрутизацию, буферизацию и доставку.

Это позволяет:

- **Снизить нагрузку на приложения:** Отправка логов по UDP — это неблокирующая операция "fire-and-forget".
- **Централизовать логику маршрутизации:** Изменение хранилища логов (например, миграция с Loki на ClickHouse) требует изменения конфигурации только в одном месте — в LogGate.
- **Обеспечить отказоустойчивость:** LogGate может буферизировать логи, если целевое хранилище временно недоступно (функционал в разработке).

## 1.2. Схема взаимодействия компонентов

```

                                      +-------------------------+
                                      |      Внешние сервисы    |
                                      +-------------------------+
                                                  |
                                                  | (UDP, JSON Logs)
                                                  v

+---------------------------------------------------------------------------------------------------+
| Docker Host |
| |
| +------------------------+ (stdout) +--------------------+ |
| | loggate-service |------------------------>| promtail | |
| | (Go App, UDP:10514) | | (Log Collector) | |
| +------------------------+ +--------------------+ |
| | ^ | (Logs) |
| | (Metrics /metrics) v |
| | | +--------------------+ |
| +----------+------------------------------------>| loki | |
| | | (Log Aggregator) | |
| v +--------------------+ |
| +------------------------+ ^ |
| | prometheus | | (LogQL Queries) |
| | (Metrics Scraper) |<------------------------+ | |
| +------------------------+ | | |
| ^ ^ | | |
| | +-------------------------------------|---------+ |
| | (PromQL) | (Queries) |
| | v |
| +------------------------+ +------------------------+ |
| | grafana | | cadvisor | |
| | (Visualization) | | (Container Metrics) | |
| +------------------------+ +------------------------+ |
| ^ |
| | (Scrape) |
| +---------------------------------------------+
| |
+---------------------------------------------------------------------------------------------------+

```

## 1.3. Описание компонентов

| Сервис                | Роль в системе                                                                                                                           | Ключевые файлы/порты                   |
| :-------------------- | :--------------------------------------------------------------------------------------------------------------------------------------- | :------------------------------------- |
| **`loggate-service`** | **Ядро системы.** Принимает логи по UDP, маршрутизирует их согласно `config.yaml` и выводит в `stdout`. Экспортирует метрики Prometheus. | `10514/udp`, `9100/tcp`, `config.yaml` |
| **`prometheus`**      | Система сбора, хранения и обработки метрик. Опрашивает `loggate`, `loki`, `promtail` и `cadvisor`.                                       | `9090/tcp`, `prometheus.yaml`          |
| **`loki`**            | Система агрегации и хранения логов. Принимает обработанные логи от `promtail`.                                                           | `3100/tcp`, `loki-config.yaml`         |
| **`promtail`**        | Агент для сбора логов. Читает `stdout` контейнера `loggate`, парсит JSON, обогащает метаданными (метками) и отправляет в Loki.           | `promtail-config.yaml`                 |
| **`grafana`**         | Платформа для визуализации. Отображает метрики из Prometheus и логи из Loki на готовом дашборде.                                         | `3000/tcp`, `grafana/provisioning/*`   |
| **`cadvisor`**        | Собирает метрики об использовании ресурсов (CPU, memory, network) всеми Docker контейнерами на хосте.                                    | `8080/tcp`                             |

## 1.4. Поток обработки лога (Data Flow)

1.  **Приём:** Внешний сервис отправляет JSON-сообщение по UDP на порт `10514`.
2.  **Декодирование:** `loggate-service` (`udp/listener.go`) принимает пакет, валидирует и декодирует его в структуру `domain.LogMessage`. Обязательные поля: `app` и `service`.
3.  **Маршрутизация:** Ядро сервиса (`service/service.go`) проверяет `routing_rules` из `config.yaml`. На основе полей `service` и/или `level` лога определяется список хранилищ-получателей (`destinations`). Если ни одно правило не подошло, используется `default_destinations`.
4.  **Буферизация:** Лог помещается во внутренний Go-канал, соответствующий каждому назначенному хранилищу. Это предотвращает блокировку входного потока.
5.  **Пакетная обработка:** Воркер для каждого хранилища накапливает логи из канала в пакет (`batch`). Пакет отправляется при достижении `batch_size` или по таймауту `batch_timeout_ms`.
6.  **Вывод:** В текущей конфигурации единственное активное хранилище — `console`. Оно сериализует каждый лог из пакета обратно в JSON и выводит в `stdout` контейнера.
7.  **Сбор Promtail:** `promtail` настроен на чтение `stdout` контейнера `loggate-service`.
8.  **Обогащение и индексация:** С помощью `pipeline_stages` в `promtail-config.yaml`, Promtail парсит JSON-строку, извлекает поля `app`, `service`, `level` и превращает их в **метки (labels) Loki**. Это ключевой шаг, который делает логи индексируемыми и позволяет быстро фильтровать их в Grafana.
9.  **Хранение:** Promtail отправляет обработанные логи с метками в Loki.
10. **Визуализация:** Пользователь открывает дашборд в Grafana, который выполняет LogQL-запросы к Loki для отображения и фильтрации логов.
